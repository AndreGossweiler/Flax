---
title: "Lewisii SAS Cox models and R plots"
output: Lewis_Flax_Cox_and_Mixed_Modeling
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## GitHub Documents

This is an R Markdown format used for publishing markdown documents to GitHub. When you click the **Knit** button all R code chunks are run and a markdown file (.md) suitable for publishing to GitHub is generated.

## SAS Code

## Mixed Modeling of Height

excel file used: **FlaxFreezeForAnalysis.xlsx**

Sheet: **V_DS_Final2**

```{SAS Height, echo=FALSE}
/* Height Data Analysis Start below */
PROC IMPORT OUT= WORK.height  /* SAS dataset name */
            DATAFILE= "~\FlaxFreezeForAnalysis.xlsx" 
            DBMS=XLSX REPLACE;
     SHEET="V_DS_Final2"; /* input dataset tab in excel sheet */
     GETNAMES=YES;
RUN;
quit;
ods trace off;
ods select all/* exclude IntPlot (persist) BoxPlot (persist)*/;
ods listing close;
ods html path='C:\Users\Documents\YourFolderPathHere\' file='HeightAnalysisAR.xls' style=default;

ods html file="Flax Height resid Analysis.htm" path="C

proc sort data=height;
by Sample_Number rep treat Time;
run;
proc mixed cl covtest data=height PLOTS=ResidualPanel(UNPACKBOX);
class rep treat Time;
model Total_HeightRegBrady = treat | Time /outp=resid2 ddfm=satterth; /* the | symbol will model model main effects and interactions (useful for 3way+ interactions.  outp tests residuals (ddfm determines degrees of freedom*/
random rep;
repeated Time/subject=rep*treat type=ar(1) rcorr; /* un ins unstuctured as the correlations between and amoung weeks may have different covariance?' */
by Sample_Number;
run;

/* Start box cox and shapiro wilks and boxcox below ##############################*/*//;
proc sort data=resid2;
by Sample_Number;
run;


proc univariate data=resid2 normal;
var resid;
by Sample_Number;
run;
quit;


/* Heritability For 2WP analysis and DOT  */ 
/* Not used in published article */
PROC IMPORT OUT= WORK.height  /* SAS dataset name */
            DATAFILE= "~C:\FlaxFreezeForAnalysis.xlsx" /* input data set filepath */
            DBMS=XLSX REPLACE;
     SHEET="Sheet1"; /* input dataset tab in excel sheet */
     GETNAMES=YES;
RUN;
quit;
proc sort data=height;
by Accession rep ;
run;
proc mixed data =height;
class rep Accession;
model HeightDOT =  ;
random rep Accession;
run;
quit;
*/ End Heritability analysis /*


### Testing Residuals and compare Tests

ods html file="Flax Height TRANSresidAnalysis.htm" path="C:\Users\Documents\FixedResidualsFilePath" gpath="C:\Users\Documents\FixedResidualsFilePath";
ods html path='C:\Users\Documents\FixedResidualsFilePath' file='HeightAnalysisARResidAdj.xls' style=default;
proc transreg data=height plots=box;
model BoxCox (Total_HeightRegBrady) = class(rep treat treat*Time Time);
by Sample_Number;
/*output out=height2;*/
run; 

%macro datatransform (sample, lambda);
data height;
set height;
if Sample_Number = &sample and &lambda ^= 0 then t_height=((Total_HeightRegBrady**(&lambda))-1)/&lambda;
run;
%mend;
%datatransform(1, 0.25); 
%datatransform(2,1);
%datatransform(3,1);
%datatransform(4,1.5);
%datatransform(5,0.75);
%datatransform(6,1.5);
%datatransform(7,0);
%datatransform(8,1);
%datatransform(9,1.25);
%datatransform(10,1);
%datatransform(11,0);
%datatransform(12,1.75);
%datatransform(13,0.5);
%datatransform(14,0.75)
%datatransform(15,0.75);
%datatransform(16,0.25);
%datatransform(17,0.75);
%datatransform(18,0.75);
%datatransform(19,1.25);
%datatransform(20,1);
%datatransform(21,0.75);
%datatransform(22,0.5);
%datatransform(23,0.75);
%datatransform(24,0.5);
%datatransform(25,0.5);
%datatransform(26,1);
%datatransform(27,0.75);
%datatransform(28,0.25);
%datatransform(29,1);
%datatransform(30,1.75);
%datatransform(31,1.5);
%datatransform(32,-0.5);
%datatransform(33,2.25);
%datatransform(34,0.75);
%datatransform(35,2);
%datatransform(36,0.75);
%datatransform(37,0.75);
%datatransform(38,0.5);
%datatransform(39,0);
%datatransform(40,1.25);
%datatransform(41,0.25);
%datatransform(42,0.25);
%datatransform(43,0.25);
%datatransform(44,2);
%datatransform(45,1.25);
%datatransform(46,1);

proc mixed cl covtest data=height PLOTS=ResidualPanel(UNPACKBOX);
class rep treat Time;
model t_height = treat | Time /outp=resid3 ddfm=satterth; /* the | symbol will model model main effects and interactions (useful for 3way+ interactions.  outp tests residuals (ddfm determines degrees of freedom*/
random rep;
repeated Time/subject=rep*treat type=ar(1) rcorr; /* un ins unstuctured as the correlations between and amoung weeks may have different covariance?' */
by Sample_Number;
run;
proc univariate data=resid3 normal plot;
var resid;
by Sample_Number;
probplot resid /normal noframe;
run;

quit;
```

## Cox Proportional Hazards

Data file needed: FlaxFreezeForAnalysis.xlsx or trialcoxNO.csv

Sheet: V_DS_Final

```{SAS}

data work.cox;
infile "/Users\Fleur\Documents\Thesis Files\Freeze Study\trialcoxNO.csv"
delimiter = ","
missover
dsd
firstobs = 2;

format Cell_Number best12.;
format Sample_Number best12.;
format treat best12.;
format rep best12.;
format SurvivalRegulated best12.;
format Time best12.;

input
Cell_Number $
Sample_Number $
treat $
rep $
SurvivalRegulated $
Time $;

run;

data cox;
set cox;
if Sample_Number="20" then delete;
if Sample_Number="26" then delete;
if Sample_Number="28" then delete;
if Sample_Number="46" then delete;
run;

/*alternative data input Below ######################## 20 26 28 46 already removed from V_DS_Final  ########################*/

PROC IMPORT OUT= WORK.cox  /* SAS dataset name */
            DATAFILE= "C:\Users\Fleur\Documents\Thesis Files\Freeze Study\FlaxFreezeForAnalysis.xlsx" /* input data set filepath */
            DBMS=XLSX REPLACE;
     SHEET="V_DS_Final"; /* input dataset tab in excel sheet */
     GETNAMES=YES;
RUN;
quit;

data cox;
set cox (drop=rep Freeze_Damage);
run;
proc sort data=cox;
by Time;
run;
data cox2;
set cox (drop=treat);
run;

ods graphics on;
ods excel file="C:\Users\Documents\YourCoxSummaryFileNameAndPathHERE.xlsx"; /* html path="C:\Users\Documents\" file="YourCoxSummaryFileNameAndPathHERE.xlsx" style=default; */

proc phreg data=cox plots(overlay)=survival;
class Sample_Number(ref='45');
model treat*SurvivalRegulated(1)=Sample_Number / TIES=Efron;
/*id Sample_Number treat;*/
/* id statement specifies additional variables for identifying observations in the input data and are placed in the out= dataset */
baseline covariates=cox2 out=Estimate3 CUMHAZ=_ALL_ survival=_all_/ rowid=Sample_Number;
hazardratio Sample_Number / diff=DISTINCT cl=BOTH;
by Time;
run;

proc sort data=Estimate3;
by Sample_Number treat Survival Time;
run;
ods excel close;
quit;

/*pull unique rows to eliminate the repeated data from the generated table. */
data first_unique_rows;
set Estimate3;
by Sample_Number treat Survival Time;
if first.Survival and first.Time; run; 

proc sort data=first_unique_rows;
by Sample_Number Time;
run;

data first_unique_rows;
set first_unique_rows (drop=Total_Dead_Stems Total_Stems Total_HeightRegBrady);
run;

```

## 

## Survival and Cumulative Hazard Plots:

Data needed **FinalsurvcumhazNOoutliers.csv**

Libraries needed:

ggplot2; dplyr; scales; ggrepel

```{r Survival and Cumulative Hazards Plots, echo=FALSE}
#Librares
#install.packages('ggrepel')

setwd("C:/Users/Fleur/Documents/Thesis Files/Freeze Study/SurvivalSAS/")
CUMHAZData=read.csv("FinalsurvcumhazNOoutliers.csv", sep = ",")

library(ggplot2)
library(dplyr)
library(scales)
library(ggrepel)

# reformat column titles
colnames(CUMHAZData)[1]<- "Sample_Number"

###To make time exclusive to 3 
CUMHAZData <- CUMHAZData%>% filter(treat!=0)
CumHazOnly3 <-CUMHAZData%>% filter(Time!=2)
CumHazOnly3 <-CumHazOnly3%>% filter(Time!=1)

#or if they have already been removed.
CumHazOnly3filt <- CumHazOnly3

##Remove number 28, 20, 26,  and 46 cause they were bad
CumHazOnly3filt <-CumHazOnly3%>% filter(Sample_Number!=46)
CumHazOnly3filt <-CumHazOnly3filt%>% filter(Sample_Number!=28)
CumHazOnly3filt <-CumHazOnly3filt%>% filter(Sample_Number!=20)
CumHazOnly3filt <-CumHazOnly3filt%>% filter(Sample_Number!=26)


##Start Surv. graph.
     s<-ggplot(CumHazOnly3filt, aes(x = as.factor(treat))) +
       geom_line(aes(y = Survival,
                     group = as.factor(Sample_Number), 
                     color = as.factor(Sample_Number))) +
       scale_y_continuous(name = "Survival Probability", breaks = seq(0,1.0,by=0.25),
                          limits = c(0,1), expand = c(0,0), oob = squish) +
       geom_text_repel(data=filter(CumHazOnly3filt,treat==15 & (Survival > .990|Sample_Number==45|Survival<0.09)), aes(y=Survival, label=Sample_Number),
                       #point.size=NA,segment.colour=NA,
  segment.alpha = 0, ## This will 'hide' the link
  segment.curvature = 0.8, segment.square = TRUE, segment.shape=-1, segment.size=0.2, segment.inflect=TRUE,
                       #segment.color = 'grey',
    box.padding = 0.5,  point.padding = 1,nudge_x = 0.15,     nudge_y = 0.9,
    force = 0.5,        hjust = "left", direction="y",  max.overlaps = 44, size= 1,xlim = c(15,16.5), ylim = c(0,NA))+
       #below is for the numbers above is for the lines...i think.
  geom_text_repel(data=filter(CumHazOnly3filt,treat==15 & (Survival > .990|Sample_Number==45|Survival< 0.09)),
                       aes(y=Survival, label=Sample_Number), segment.curvature = 0.7, segment.square = TRUE, segment.inflect= TRUE, segment.color = 'grey', box.padding = 0.3, point.padding = 0.1, nudge_x = 1.7,    nudge_y = 0.7, force = 0.5,   hjust = 0.5, direction="y", na.rm = TRUE,  ylim = c(0,NA))+
       theme(legend.position = "right",
             panel.grid.minor.y = element_blank(),
             panel.grid.major.x = element_blank())+
       labs(x = "Temperature (*-1°C)", y = "Survival probability", color = "Accession") +
       ggtitle(" ")
print(s)
     
#### Cumulative hazard Start

c<-ggplot(CumHazOnly3filt,aes(x=as.factor(treat)))+
       geom_line(aes(x=as.factor(treat),y=CumHaz,group=as.factor(Sample_Number),color=as.factor(Sample_Number)))+
      scale_y_continuous(name = "Cumulative Hazard", breaks = seq(0,2.0,by=0.5), limits= c(0,3.5),expand = c(0,0), oob=squish)+
       #25 and 32 are off the scale
       geom_text_repel(data=filter(CumHazOnly3filt,treat==15 & (CumHaz > 1|Sample_Number==45|CumHaz<0.09)),
                       aes(y=CumHaz, label=Sample_Number),
                      segment.alpha = 0, segment.curvature = 0.8, segment.square = TRUE, segment.shape=-1, segment.size=0.2, segment.inflect=TRUE, box.padding = 0.5, point.padding = 1, nudge_x = 0.15, nudge_y = 0.9, force = 0.5, hjust = "left", direction="y", max.overlaps = 44, size= 1,xlim = c(15,16.5), ylim = c(0,3.5))+
      geom_text_repel(data=filter(CumHazOnly3filt,treat==15 & (CumHaz > 1|Sample_Number==45|CumHaz< 0.09)),
                       aes(y=CumHaz, label=Sample_Number),
                       segment.curvature = 0.7, segment.square = TRUE, segment.inflect= TRUE, segment.color = 'grey', box.padding = 0.3, point.padding = 0.1, nudge_x = 1.7, nudge_y = 0.7, force = 0.5, hjust = 0.5, direction="y", na.rm = TRUE, ylim = c(0,NA))+
       theme(legend.position = "none",
             panel.grid.minor.y = element_blank(),
             panel.grid.major.x = element_blank())+
       labs(x = "Treatment Temperature (*-1°C)")
     print(c)   
     
### To use log scale alter the following lines
    
     c<-ggplot(CumHazOnly3filt,aes(x=as.factor(treat)))+
       geom_line(aes(x=as.factor(treat),y=CumHaz,group=as.factor(Sample_Number),color=as.factor(Sample_Number)))+
       # geom_errorbar(aes(ymin=LowerCumHaz, ymax=UpperCumHaz,x=as.factor(treat), group=as.factor(Sample_Number),color=as.factor(Sample_Number)), width=0.05)+
       scale_y_continuous(name = "Cumulative Hazard", trans = "log10")+
       #add the trans line in place of the above code in s_y_c() for log scale.
       #trans = "log10"
       #25 and 32 are off the scale
       #  scale_y_continuous(waiver(), sec.axis = dup_axis(~.+2))+
       geom_text_repel(data=filter(CumHazOnly3filt,treat==15 & (CumHaz > 1|Sample_Number==45|CumHaz<0.09)),
                       aes(y=CumHaz, label=Sample_Number),
                       #point.size=NA,segment.colour=NA,
                       segment.alpha = 0, ## This will 'hide' the link
                       segment.curvature = 0.8,
                       segment.square = TRUE,
                       segment.shape=-1,
                       segment.size=0.2,
                       segment.inflect=TRUE,
                       #segment.color = 'grey',
                       box.padding = 0.5,
                       point.padding = 1,
                       nudge_x = 0.15,
                       nudge_y = 5,
                       force = 0.5,
                       hjust = "left",
                       direction="y",
                       max.overlaps = 44, size= 1,xlim = c(15,16.5),
                       ylim = c(0,NA))+
       #below is for the numbers above is for the lines...i think.
       geom_text_repel(data=filter(CumHazOnly3filt,treat==15 & (CumHaz > 1|Sample_Number==45|CumHaz< 0.09)),
                       aes(y=CumHaz, label=Sample_Number),
                       segment.curvature = 0.7,
                       segment.square = TRUE,
                       segment.inflect= TRUE,
                       segment.color = 'grey',
                       box.padding = 0.3,
                       point.padding = 0.1,
                       nudge_x = 1.7,
                       nudge_y = 5,
                       force = 0.5,
                       hjust = 0.5,
                       direction="y",
                       na.rm = TRUE, 
                       ylim = c(0,NA))+
       #coord_cartesian(ylim=c(0,2.1))+ 
       #coord_cartesian(ylim = c(4.1,5.3), y = "secondary")+
       #geom_point(aes(y=StdErrCumHaz, group=as.factor(Sample_Number), color="STDError"))+
       theme(legend.position = "none",
             #legend.title = element_text(), 
             #axis.title.y = element_text(),
             panel.grid.minor.y = element_blank(),
             panel.grid.major.x = element_blank())+
       labs(x = "Treatment Temperature (*-1°C)")
     print(c)   
       #labs(title = "Treatment effects of Cumulative Hazard across Treatment", 
           # x = "", y="Cumulative Hazard")
     
   #  ggsave(paste0("/Users/Fleur/Documents/Thesis Files/Freeze Study/Figures/Survival/CumulativeHazardlogplot",".png"))
     
     
          
```

## Post Treatment Height Trend Graphs

Data file name: **MasterFreezeData111422.csv**

**Extract CSV** version of Sheet: Vertical_MDS from **FlaxFreezeForAnalysis.xlsx**

Libraries and Packages needed

download.packages(Rmisc)

library(ggplot2), library(hrbrthemes), library(GGally), library(viridis), library(dplyr)

```{r Height Graphs, echo=FALSE}
HeightData=read.csv("MasterFreezeData111422.csv", sep = ",")

library(ggplot2)
library(hrbrthemes)
library(GGally)
library(dplyr)

#Establish a colourblind accessible colour palatte
cbbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")


#Find each mean height by ...
HeightData %>% group_by(Sample_Number,Time, treat) %>% 
  summarise_at(vars("Total_HeightRegBrady"),mean, na.rm=T) -> df

for (var in unique(df$Sample_Number)) {
   dev.new()
   x<-  ggplot(df[df$Sample_Number==var,],aes(x=Time, y=Height (cm)))+ geom_line(aes(Time,Total_HeightRegBrady,group=as.factor(treat),colour=as.factor(treat)))+
    scale_color_manual(values = cbbPalette)+
    theme_ipsum()+
    theme(
      legend.title = element_text(face="bold"),
      axis.text = element_text(face="bold"),
      axis.text.x = element_text(face="bold"),
      axis.text.y = element_text(face="bold"),
      axis.title.y = element_text(hjust=0.5, face="bold"),
      axis.title.x = element_text(hjust=0.5, face="bold"),
      legend.position="right",
      plot.title = element_text(size=16),
      #legend(x = "topright", legend = legendlabels, bty = "n")
      )+
    ylim(0,200)+
    labs(x="Time (week)",y="Height (cm)",colour="Temperature Treatment (°C)")+
    #To remove the title
     #ggtitle(" ") 
    ggtitle(paste0(var))
   #Save each graph individually
   #ggsave(paste0("/Users/Documents/YourFileNameHere",var,".png"))
    print(x) 
   } 
```

## Temperature Sensor Graphs

Data File Needed: GrowthChamberTemperatures.xlsx

**Extract CSV** version of GrowthChamberTemperatures

Change TrialTemp to a **positive** integer

Libraries used:

library(hrbrthemes), library(GGally), library(viridis), library(tidyr)

```{r Temperature Sensor Graphs, echo=FALSE}

BNCTemps=read.csv("GrowthChamberTemperatures.csv", sep = ",")
library(dplyr)
library(lubridate)
TempReads<- BNCTemps %>% select('DateNTime','ChamberPoint1', 'ChamberPoint2', 'ChamberSetPoint',
                                'TrialTEMP2', 'Averagetemp')
#data binning step for Time data; NOT USED IN Graph below
class(TempReads$DateNTime)
TempReads$DateNTime<-as.POSIXct(TempReads$DateNTime, format="%m/%d/%Y %H:%M",tz=Sys.timezone())
BinTime<-cut(TempReads$DateNTime, breaks="6 mins", labels=FALSE)
df3<-cbind(TempReads,BinTime)
BinTemps<-aggregate(df3$Averagetemp, list(df3$BinTime), FUN=mean)
#Mean based on BinTime group value
df4<-df3 %>% group_by(BinTime) %>% mutate(BinTemps=mean(Averagetemp))
df5<-df4 %>% group_by(BinTime) %>% mutate(BinChamberP1=mean(ChamberPoint1))
head(df5)
##For Final graph jump to bottom

#librarys for ggplot
library(hrbrthemes)
library(GGally)
library(viridis)
library(tidyr)

for (var in unique(df5$TrialTEMP2)) {
  dev.new()
  x<-ggplot(df5[df5$TrialTEMP2==var,],aes(DateNTime,BinTemps,group=1,color="BinTemps"))+
    geom_line()+geom_line(aes(y=BinChamberP1,color="BinChamberP1"))+
    geom_line(aes(y=ChamberSetPoint,color="ChamberSetPoint"))+
    theme(
      axis.text = element_text(face="bold"),
      axis.text.x = element_text(face="bold"),
      axis.text.y = element_text(face="bold"),
      axis.title.y = element_text(face="bold"),
      axis.title.x = element_text(face="bold"),
      legend.position="right",
      plot.title = element_text(size=15)
    )+
    scale_y_continuous(breaks = seq(-20,10,2))+
    scale_colour_manual(values = c("green","red","blue"),labels=c("Avg Cell Temp","Avg Chamber Sensor","Chamber Set Point"))+
    labs(x="Time", y="Temperature (°C)",colour="Temperature Sensor Type")+
    ggtitle(" ")
  #ggtitle(paste0("Temperature observations during -",var,"°C treatment"))
  #use above line ^ to put title back onto graph
  print(x)
  #to save each graph by Treatment, below
  #ggsave(paste0("/Users/Documents/YourFileNameHere",var,".png"))
} 


```

## C**orrelation Data Transformations**

Data transformation performed by SAS and R for height data for correlation tests is listed below. **Orders of operations may not be conserved** as alternation between the two software was done multiple times. It is **not recommended** to perform these transformations this way, instead I recommend to remain in one software for all data steps. The steps below were provided for transparency only.

```{SAS}
PROC IMPORT OUT= WORK.HeightAvg  /* SAS dataset name */
            DATAFILE= "C:\Users\Fleur\Documents\Thesis Files\Freeze Study\HeightAvg.xlsx" /* input data set filepath */
            DBMS=XLSX REPLACE;
     SHEET="Sheet1"; /* input dataset tab in excel sheet */
     GETNAMES=YES;
RUN;
quit;
proc sort data = Heightavg;
by Sample_Number treat Time;
run;
proc transpose data = Heightavg out=Heightavg_wide(drop=_name_ _LABEL_);
by Sample_Number treat;
var Total_HeightRegBrady;
id Time;
run;
proc export data=Heightavg_wide
outfile="C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Heightavg_wide.csv" /* input data set filepath */
            DBMS=csv 
replace; run;

/* Start of Correlation testing ######################################## */

PROC IMPORT OUT= WORK.VDS  /* SAS dataset name */
            DATAFILE= "C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Correlation tests\FlaxGeoInfo.xlsx " /* input data set filepath */
            DBMS=XLSX REPLACE;
     SHEET="V_DS_Final"; /* input dataset tab in excel sheet */
     GETNAMES=YES;
RUN;
quit; 

proc sort data = VDS;
by Sample_Number treat Time;
run;
proc transpose data = VDS out=VDS_wide(drop=_name_ _LABEL_);
by Sample_Number treat rep;
var SurvivalRegulated;
id Time;
run;

proc export data=VDS_wide
outfile="C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Correlation tests\VDS_wide.csv" /* input data set filepath */
            DBMS=csv 
replace; run;

PROC IMPORT OUT= WORK.SurvAvg  /* SAS dataset name */
            DATAFILE= "C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Correlation tests\SurvTry2.xlsx " /* input data set filepath */
            DBMS=XLSX REPLACE;
     SHEET="Sheet 1"; /* input dataset tab in excel sheet */
     GETNAMES=YES;
RUN;
quit; 

proc sort data=SurvAvg ;
by Sample_Number treat Time;
run;
proc transpose data = SurvAvg out=SurvAvg_wide (drop=_name_ _LABEL_) ;
by Sample_Number treat;
var SurvivalRegulated;
id Time;
run;
proc export data=SurvAvg_wide
outfile="C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Correlation tests\SurvAvg_wide.csv" /* input data set filepath */
            DBMS=csv 
replace; run;


/* Export to R to get averages easily then reimport to run corr. */

proc export data=Vds_wide
outfile="C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Correlation tests\Surv_wide.csv" /* input data set filepath */
            DBMS=csv 
replace; run;

PROC IMPORT OUT= WORK.HeightDiff  /* SAS dataset name */
            DATAFILE= "C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Correlation tests\FlaxGeoInfo.xlsx " /* input data set filepath */
            DBMS=XLSX REPLACE;
     SHEET="V_DS_Final"; /* input dataset tab in excel sheet */
     GETNAMES=YES;
RUN;
quit; 

proc sort data=HeightDiff ;
by Sample_Number rep treat Time;
run;
proc transpose data = HeightDiff out=HeightDiff_wide (drop=_name_ _LABEL_) ;
by Sample_Number rep treat;
var Total_HeightRegBrady;
id Time;
run;

data HeightDiff2_wide;
set HeightDiff_wide;
BaselineOne = (_1-_0);
BaselineTwo = (_2-_1);
BaselineThree = (_3-_2);
run;
quit;

proc export data=HeightDiff2_wide
outfile="C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Correlation tests\HeightDifAvg_wide.csv" /* input data set filepath */
            DBMS=csv 
replace; run;


```

The R code for height and survival means

new libraries used: library(openxlsx), library(writexl)

```{r}
library(dplyr)
setwd("C:/Users/Fleur/Documents/Thesis Files/Freeze Study/Correlation tests")
WideSurvData=read.csv("Surv_wide.csv", sep = ",")
SURVTIME<-WideSurvData
head(SURVTIME)
colnames(SURVTIME)<- c('Sample_Number','treat','0','1','2','3')
WideSurvData %>% group_by(Sample_Number, treat) %>% 
  summarise_at(vars("ST3"),mean, na.rm=T) -> SURVTIME3


WideTry2=read.csv("VDSExcel.csv", sep = ",")
#Vertical_MDS in FlaxFreezeforAnalysis
WideTry2 %>% group_by(Sample_Number, Time, treat) %>% 
  summarise_at(vars("SurvivalRegulated"),mean, na.rm=T) -> SurvTry2
WideTry2 %>% group_by(Sample_Number, Time, treat) %>% 
  summarise_at(vars("Freeze_Damage"),mean, na.rm=T) -> FreezeAvg
HeightWide=read.csv("HeightDifAvg_wide.csv", sep = ",")
HeightWide %>% group_by(Sample_Number, treat) %>% 
  summarise_at(vars("BaselineOne"),mean, na.rm=T) ->Base1Avg
HeightWide %>% group_by(Sample_Number, treat) %>% 
  summarise_at(vars("BaselineTwo"),mean, na.rm=T) ->Base2Avg
HeightWide %>% group_by(Sample_Number, treat) %>% 
  summarise_at(vars("BaselineThree"),mean, na.rm=T) ->Base3Avg

Column2toadd<- Base2Avg$BaselineTwo
Column3toadd<- Base3Avg$BaselineThree
Base1Avg<-cbind(Base1Avg,Column2toadd,Column3toadd)
colnames(Base1Avg)<- c('Sample_Number','treat','0to1Avg','1to2Avg','2to3Avg')

library(openxlsx)
openxlsx::write.xlsx(SurvTry2, "SurvTry2.xlsx", rowNames=FALSE)
openxlsx::write.xlsx(FreezeAvg, "FreezeAvg.xlsx", rowNames=FALSE)
openxlsx::write.xlsx(Base1Avg, "HeightGrowthAvg.xlsx", rowNames=FALSE)


```

## C**orrelation Test Data Transformations**

File needed: **FlaxGeoInfo.xlsx**

Sheets: FullWideAvg, 9only, 12only, 15only

```{SAS Correlations}
PROC IMPORT OUT= WORK.cortest  /* SAS dataset name */
            DATAFILE= "C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Correlation tests\FlaxGeoInfo.xlsx " /* input data set filepath */
            DBMS=XLSX REPLACE;
     SHEET="FullWideAvg"; /* input dataset tab in excel sheet */
     GETNAMES=YES;
RUN;
quit; 


Proc corr data=cortest pearson plots=scatter(nvar=all); 
 Var ElevationM Latitude Longitude Hazard _0to1Avg _1to2Avg _2to3Avg HT_0 HT_1 HT_2 HT_3 Freeze_Damage ;
run;
ods output Correlations=cortest;
quit;

/* Correlations by treatments below */


PROC IMPORT OUT= WORK.only9corr  /* SAS dataset name */
            DATAFILE= "C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Correlation tests\FlaxGeoInfo.xlsx " /* input data set filepath */
            DBMS=XLSX REPLACE;
     SHEET="9only"; /* input dataset tab in excel sheet */
     GETNAMES=YES;
RUN;
quit; 
Proc corr data=only9corr pearson plots=scatter(nvar=all); 
 Var ElevationM Latitude Longitude Hazard _0to1Avg _1to2Avg _2to3Avg HT_0 HT_1 HT_2 HT_3 ;
run;
ods output Correlations=only9corr;

PROC IMPORT OUT= WORK.only15corr  /* SAS dataset name */
            DATAFILE= "C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Correlation tests\FlaxGeoInfo.xlsx " /* input data set filepath */
            DBMS=XLSX REPLACE;
     SHEET="15only"; /* input dataset tab in excel sheet */
     GETNAMES=YES;
RUN;
quit; 
Proc corr data=only15corr pearson plots=scatter(nvar=all); 
 Var ElevationM Latitude Longitude Hazard _0to1Avg _1to2Avg _2to3Avg HT_0 HT_1 HT_2 HT_3 ;
run;
ods output Correlations=only15corr;
PROC IMPORT OUT= WORK.only12corr  /* SAS dataset name */
            DATAFILE= "C:\Users\Fleur\Documents\Thesis Files\Freeze Study\Correlation tests\FlaxGeoInfo.xlsx " /* input data set filepath */
            DBMS=XLSX REPLACE;
     SHEET="12only"; /* input dataset tab in excel sheet */
     GETNAMES=YES;
RUN;
quit; 
Proc corr data=only12corr pearson plots=scatter(nvar=all); 
 Var ElevationM Latitude Longitude Hazard _0to1Avg _1to2Avg _2to3Avg HT_0 HT_1 HT_2 HT_3 ;
run;
ods output Correlations=only12corr;
```

## **RDA analysis**

```{r}
#devtools::install_github("jimhester/archive") #for CHELSA climate data
#remotes::install_github("MirzaCengic/climatedata") #for CHELSA climate data
#install.packages("cli")
library(cli)
#install.packages("dplyr")
library(dplyr)
library(magrittr)
#install.packages("ggplot2")
library(ggplot2)
#library(interactions) #for interaction plots
#install.packages("raster")
library(raster)
library(sp)
library(rgdal)
library(remotes)
#install.packages("climatedata")
library(climatedata)
#library(AICcmodavg)
#install.packages("lme4")
library(lme4)
library(lmerTest)
#library(arm) #for se.ranef()
library(vegan)
#install.packages("ggrepel")
library(ggrepel)
install.packages('ggvegan')
library(ggvegan)
library(lubridate)

env_data <- read.csv("~/Thesis Files/BioClim/Freeze_Seed_Geo_Collection.csv", header=T)

env_data <- env_data[,-1]

env_data <- env_data %>% mutate(source = 1:46)
 
# %>% #keep only pops that have coordinates (missing coords for source 37, and Appar doesn't have coords)
 # mutate(Lat_s=scale(Lat), Long_s=scale(Long), Elev_m_s=scale(Elev_m)) # scale predictors
rownames(env_data) <- env_data[,1]
head(env_data)

geo_data <- env_data %>% dplyr::select(population,Lat,Long,Elev_m) %>%
  filter(!is.na(Lat) | !is.na(Long))
#BioClim_codes <- read.csv("~/Thesis Files/BioClim/BioClim_codes.csv") #this file matches the vague bioclim codes (e.g. bio01) with actual descriptions (e.g. Mean Annual Temp)

dem2<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio6_1981-2010_V.2.1.tif")
coords <- data.frame(Long=env_data$Long, Lat=env_data$Lat,
                     row.names = env_data$population) %>% na.omit()

points <- SpatialPoints(coords, dem@crs)

bio06 <- raster::extract(dem, points,sp=F) #previously raster::extract(r,points)

clim_data <- cbind.data.frame(coordinates(points),bio06) %>%
  tibble::rownames_to_column("source")
clim_data2<-clim_data
clim_data2<-geo_data


bio10<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio10_1981-2010_V.2.1.tif")
bio11<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio11_1981-2010_V.2.1.tif")
bio12<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio12_1981-2010_V.2.1.tif")
bio13<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio13_1981-2010_V.2.1.tif") 
bio14<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio14_1981-2010_V.2.1.tif") 
bio15<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio15_1981-2010_V.2.1.tif") 
bio16<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio16_1981-2010_V.2.1.tif")
bio17<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio17_1981-2010_V.2.1.tif" )
bio18<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio18_1981-2010_V.2.1.tif")
bio19<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio19_1981-2010_V.2.1.tif") 
bio1<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio1_1981-2010_V.2.1.tif" )
bio2<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio2_1981-2010_V.2.1.tif" )
bio3<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio3_1981-2010_V.2.1.tif" )
bio4<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio4_1981-2010_V.2.1.tif" )
bio5<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio5_1981-2010_V.2.1.tif" )
#bio6<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio6_1981-2010_V.2.1.tif" )
bio7<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio7_1981-2010_V.2.1.tif") 
bio8<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio8_1981-2010_V.2.1.tif")
bio9<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio9_1981-2010_V.2.1.tif") 
#bio6<-raster("https://os.zhdk.cloud.switch.ch/envicloud/chelsa/chelsa_V2/GLOBAL/climatologies/1981-2010/bio/CHELSA_bio6_1981-2010_V.2.1.tif")
dem<-raster("~/Thesis Files/BioClim/CHELSA_bio6_1981-2010_V.2.1.tif")

bio1points <- SpatialPoints(coords, bio1@crs)
bio01 <- raster::extract(bio1, bio1points,sp=F) #previously raster::extract(r,points)
bio1_data <- cbind.data.frame(coordinates(bio1points),bio01) %>%
  tibble::rownames_to_column("source")

bio2points <- SpatialPoints(coords, bio2@crs)
bio02 <- raster::extract(bio2, bio2points,sp=F) #previously raster::extract(r,points)

bio3points <- SpatialPoints(coords, bio3@crs)
bio03 <- raster::extract(bio3, bio3points,sp=F) #previously raster::extract(r,points)

bio4points <- SpatialPoints(coords, bio4@crs)
bio04 <- raster::extract(bio4, bio4points,sp=F) #previously raster::extract(r,points)

bio5points <- SpatialPoints(coords, bio5@crs)
bio05 <- raster::extract(bio5, bio5points,sp=F) #previously raster::extract(r,points)

#dem
#bio6points <- SpatialPoints(coords, bio2@crs)
#bio06 <- raster::extract(bio2, bio2points,sp=F) #previously raster::extract(r,points)

bio7points <- SpatialPoints(coords, bio7@crs)
bio07 <- raster::extract(bio7, bio7points,sp=F) #previously raster::extract(r,points)

bio8points <- SpatialPoints(coords, bio8@crs)
bio08 <- raster::extract(bio8, bio8points,sp=F) #previously raster::extract(r,points)

bio9points <- SpatialPoints(coords, bio9@crs)
bio09 <- raster::extract(bio9, bio9points,sp=F) #previously raster::extract(r,points)

bio10points <- SpatialPoints(coords, bio10@crs)
bio10 <- raster::extract(bio10, bio10points,sp=F) #previously raster::extract(r,points)

bio11points <- SpatialPoints(coords, bio11@crs)
bio11 <- raster::extract(bio11, bio11points,sp=F) #previously raster::extract(r,points)

bio12points <- SpatialPoints(coords, bio12@crs)
bio12 <- raster::extract(bio12, bio12points,sp=F) #previously raster::extract(r,points)

bio13points <- SpatialPoints(coords, bio13@crs)
bio13 <- raster::extract(bio13, bio13points,sp=F) #previously raster::extract(r,points)

bio14points <- SpatialPoints(coords, bio14@crs)
bio14 <- raster::extract(bio14, bio14points,sp=F) #previously raster::extract(r,points)

bio15points <- SpatialPoints(coords, bio15@crs)
bio15 <- raster::extract(bio15, bio15points,sp=F) #previously raster::extract(r,points)

bio16points <- SpatialPoints(coords, bio16@crs)
bio16 <- raster::extract(bio16, bio16points,sp=F) #previously raster::extract(r,points)

bio17points <- SpatialPoints(coords, bio17@crs)
bio17 <- raster::extract(bio17, bio17points,sp=F) #previously raster::extract(r,points)

bio18points <- SpatialPoints(coords, bio18@crs)
bio18 <- raster::extract(bio18, bio18points,sp=F) #previously raster::extract(r,points)

bio19points <- SpatialPoints(coords, bio19@crs)
bio19 <- raster::extract(bio19, bio19points,sp=F) #previously raster::extract(r,points)


Elev_m<-geo_data$Elev_m
clim_data2<-cbind(bio1_data,bio02,bio03,bio04,bio05,
                  bio06,bio07,bio08,bio09,bio10,
                  bio11,bio12,bio13,bio14,bio15,
                  bio16,bio17,bio18,bio19,Elev_m)
#adjust the scale manually refer to chelsa website for more detail
clim_data2[,4] <- (clim_data2[,4]*0.1)-273.15
clim_data2[,5] <- (clim_data2[,5]*0.1)
clim_data2[,6] <- (clim_data2[,6]*0.1)
clim_data2[,7] <- (clim_data2[,7]*0.1)
clim_data2[,8] <- (clim_data2[,8]*0.1)-273.15
clim_data2[,9] <- (clim_data2[,9]*0.1)-273.15
clim_data2[,10] <- (clim_data2[,10]*0.1)
clim_data2[,11] <- (clim_data2[,11]*0.1)-273.15
clim_data2[,12] <- (clim_data2[,12]*0.1)-273.15
clim_data2[,13] <- (clim_data2[,13]*0.1)-273.15
clim_data2[,14] <- (clim_data2[,14]*0.1)-273.15
clim_data2[,15] <- (clim_data2[,15]*0.1)
clim_data2[,16] <- (clim_data2[,16]*0.1)
clim_data2[,17] <- (clim_data2[,17]*0.1)
clim_data2[,18] <- (clim_data2[,18]*0.1)
clim_data2[,19] <- (clim_data2[,19]*0.1)
clim_data2[,20] <- (clim_data2[,20]*0.1)
clim_data2[,21] <- (clim_data2[,21]*0.1)
clim_data2[,22] <- (clim_data2[,22]*0.1)

env_pca_df <- clim_data2
head(env_pca_df)
rownames(env_pca_df) <- env_pca_df$source
env_pca_df <- env_pca_df %>% dplyr::select(-c(source))

my_env_pca <- rda(env_pca_df2, scale = T) #PCA of scaled geo and clim vars (skip column 1 and 2 which have source/population ID)
summary(my_env_pca)
summary(eigenvals(my_env_pca))[2,1:12] #percent variance explained
env_pca_eigenvals <- round(summary(eigenvals(my_env_pca))[,1:3], digits = 3)
summary(env_pca_eigenvals)

##This was adapted from and with assistance from Peter Innes (Innes et al. 2022)
freeze_data <- read.csv("~/RDA_Accession.csv", header=T)
head(freeze_data)
summary(freeze_data_cut)
freeze_data_cut <-freeze_data[,-1]
freeze_data2 <- freeze_data_cut %>% mutate(source = 1:41)
rownames(freeze_data_cut)<- freeze_data_cut[,1]

env_pca_df2<- subset(env_pca_df, Elev_m != 1966.0)
#cut out 
env_pca_df2<- subset(env_pca_df2, Elev_m != 3183.0)
#cut out carbonate creek
env_pca_df2<- subset(env_pca_df2, Elev_m != 2408.1)
freeze_data_cut2 <-freeze_data_cut[,-1]

my_full_rda <- rda(freeze_data_cut2 ~ ., data=env_pca_df2, scale = T)
summary(my_full_rda)
my_full_rda2<- data.frame(scores(my_full_rda, choices = 1:2, display = "species", scaling = 0)) %>%
  tibble::rownames_to_column("var") %>%
  full_join(dplyr::select(BioClim_codes, var, description)) %>%
  relocate(description, .after = var)
my_full_rda3<- data.frame(scores(my_full_rda, choices = 1:2, display = "sites", scaling = 0)) %>%
  tibble::rownames_to_column("var") %>%
  full_join(dplyr::select(BioClim_codes, var, description)) %>%
  relocate(description, .after = var)

mv_rda.sp_sc <- data.frame(scores(my_full_rda, choices = 1:2, scaling = 0, display="sp"))
mv_rda.env_sc <- data.frame(scores(my_full_rda, choices = 1:2, scaling = 0, display = "bp"))
mv_rda.site_sc <- data.frame(scores(my_full_rda, choices = 1:2, scaling = 0, display = "wa"))

mv_rda_eigenvals <- round(summary(eigenvals(my_full_rda, model = "constrained"))[,1:4], digits = 3) #constrained by climate
mv_rda_eigenvals_adj <- round(rbind(mv_rda_eigenvals["Eigenvalue",], data.frame(mv_rda_eigenvals[2:3,]) * RsquareAdj(my_full_rda)[2]), digits = 3) #loadings adjusted by adjusted R squared.
rownames(mv_rda_eigenvals_adj)[1] <- "Eigenvalue"

anova.cca(my_full_rda, permutations=1000)
anova.cca(my_full_rda, by="margin", permutations=1000)
anova.cca(my_full_rda, by="terms", permutations=1000) 
anova.cca(my_full_rda, by="axis", permutations=1000)
anova_rda_full<-rbind(anova_rda,anova2,anova3,anova4)

mv_rda_triplotgg_SUPP <- ggplot() +
  geom_point(data=mv_rda.site_sc, aes(x = RDA1, y = RDA2), size=2, alpha=0.5) +
  #geom_text(data=mv_rda.site_sc, aes(x = RDA1, y = RDA2, label=rownames(mv_2da.site_sc)), hjust=0, vjust=0, size=4, alpha=.5) +
  #geom_text_repel(data=mv_full_rda, aes(x = RDA1, y = RDA2, label=Label), size=4, alpha=0.5, max.overlaps = 11) +
  geom_segment(data=mv_rda.sp_sc, aes(x=0, xend=RDA1, y=0, yend=RDA2), 
               color="red", arrow=arrow(length=unit(.02, "npc"))) +
  geom_text_repel(data=mv_rda.sp_sc, 
                  aes(x=RDA1,y=RDA2,label=rownames(mv_rda.sp_sc)), 
                  color="red", size=4) +
  geom_segment(data=mv_rda.env_sc, aes(x=0, xend=RDA1, y=0, yend=RDA2), 
               color="blue", alpha=0.5, arrow=arrow(length=unit(.02,"npc"))) +
  geom_text_repel(data=mv_rda.env_sc, 
                  aes(x=RDA1,y=RDA2,label=rownames(mv_rda.env_sc)), 
                  color="blue", alpha=0.5, size=4) +
  geom_text_repel(data=mv_rda.site_sc, aes(x = RDA1, y = RDA2, label=rownames(mv_rda.site_sc)), size=4, alpha=0.5) +
 
  labs(x=paste0("RDA1 ","(",100*mv_rda_eigenvals_adj[2,1],"%)"), y=paste0("RDA2 ", "(",100*mv_rda_eigenvals_adj[2,2],"%)"), title="") +
  theme_bw() +
  theme(text = element_text(size = 14))
print(mv_rda_triplotgg_SUPP)
```
